{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSC 180 Intelligent Systems \n",
    "\n",
    "#### William Lorence\n",
    "\n",
    "#### California State University, Sacramento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Modern Low Footprint Cyber Attack Protection\n",
    "## Reading the Data\n",
    "The code below reads the data from the dataset and creates dataframes. Values of \"-\" are treated as N/A and entries with this value are dropped from the dataframe. The \"attack_cat\" column has been dropped to decrease the likelihood of model overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81173\n",
      "35179\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>dur</th>\n",
       "      <th>proto</th>\n",
       "      <th>service</th>\n",
       "      <th>state</th>\n",
       "      <th>spkts</th>\n",
       "      <th>dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>rate</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>is_ftp_login</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_flw_http_mthd</th>\n",
       "      <th>ct_src_ltm</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>is_sm_ips_ports</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.681642</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>628</td>\n",
       "      <td>770</td>\n",
       "      <td>13.677108</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>2.093085</td>\n",
       "      <td>tcp</td>\n",
       "      <td>smtp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>62</td>\n",
       "      <td>28</td>\n",
       "      <td>56329</td>\n",
       "      <td>2212</td>\n",
       "      <td>42.520967</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>udp</td>\n",
       "      <td>snmp</td>\n",
       "      <td>INT</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>500000.001300</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.393556</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>860</td>\n",
       "      <td>1096</td>\n",
       "      <td>43.195886</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.338017</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>FIN</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>998</td>\n",
       "      <td>268</td>\n",
       "      <td>44.376468</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id       dur proto service state  spkts  dpkts  sbytes  dbytes  \\\n",
       "3    4  1.681642   tcp     ftp   FIN     12     12     628     770   \n",
       "11  12  2.093085   tcp    smtp   FIN     62     28   56329    2212   \n",
       "15  16  0.000002   udp    snmp   INT      2      0     138       0   \n",
       "17  18  0.393556   tcp    http   FIN     10      8     860    1096   \n",
       "21  22  0.338017   tcp    http   FIN     10      6     998     268   \n",
       "\n",
       "             rate  ...  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "3       13.677108  ...                 1                 1               3   \n",
       "11      42.520967  ...                 1                 1               2   \n",
       "15  500000.001300  ...                 1                 1               4   \n",
       "17      43.195886  ...                 1                 1               2   \n",
       "21      44.376468  ...                 1                 1               1   \n",
       "\n",
       "    is_ftp_login  ct_ftp_cmd  ct_flw_http_mthd  ct_src_ltm  ct_srv_dst  \\\n",
       "3              1           1                 0           2           1   \n",
       "11             0           0                 0           1           1   \n",
       "15             0           0                 0           2           1   \n",
       "17             0           0                 1           1           3   \n",
       "21             0           0                 1           2           3   \n",
       "\n",
       "    is_sm_ips_ports  label  \n",
       "3                 0      0  \n",
       "11                0      0  \n",
       "15                0      0  \n",
       "17                0      0  \n",
       "21                0      0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "path = \"./dataset/\"\n",
    "save_path = \"./models/\"\n",
    "\n",
    "#Defines filepaths for the data sets\n",
    "training_set = os.path.join(path,\"UNSW_NB15_training-set.csv\")\n",
    "test_set = os.path.join(path,\"UNSW_NB15_test-set.csv\")\n",
    "\n",
    "#Loads files into dataframes\n",
    "df_training_set = pd.read_csv(training_set, na_values = ['-'])\n",
    "df_test_set = pd.read_csv(test_set, na_values = ['-'])\n",
    "\n",
    "#Removes rows with a \"-\" in any column\n",
    "df_training_set.dropna(inplace = True)\n",
    "df_test_set.dropna(inplace = True)\n",
    "\n",
    "#Drop the \"attack_cat\" column from both the training and test datasets\n",
    "df_training_set.drop(columns=['attack_cat'], inplace = True)\n",
    "df_test_set.drop(columns=['attack_cat'], inplace = True)\n",
    "\n",
    "print(len(df_training_set))\n",
    "print(len(df_test_set))\n",
    "\n",
    "df_training_set.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Filtering\n",
    "The code below removes categorical values that are not present in both datasets. As visible via the print statements, roughly 600 entries are dropped from the training set, while only one is dropped from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'udp', 'tcp'}\n",
      "{'udp', 'tcp'}\n",
      "{'tcp', 'udp'}\n",
      "{'smtp', 'irc', 'radius', 'ssl', 'ssh', 'dns', 'snmp', 'ftp-data', 'pop3', 'http', 'ftp', 'dhcp'}\n",
      "{'smtp', 'irc', 'radius', 'ssl', 'ssh', 'dns', 'snmp', 'ftp-data', 'pop3', 'http', 'ftp', 'dhcp'}\n",
      "{'smtp', 'irc', 'radius', 'ssl', 'ssh', 'dns', 'snmp', 'ftp-data', 'pop3', 'http', 'ftp', 'dhcp'}\n",
      "{'CON', 'INT', 'RST', 'FIN', 'REQ'}\n",
      "{'CON', 'REQ', 'INT', 'FIN', 'ACC'}\n",
      "{'CON', 'INT', 'FIN', 'REQ'}\n",
      "{'Backdoor', 'Fuzzers', 'Worms', 'Analysis', 'Generic', 'DoS', 'Exploits', 'Normal', 'Reconnaissance'}\n",
      "{'Backdoor', 'Fuzzers', 'Worms', 'Generic', 'DoS', 'Exploits', 'Normal', 'Reconnaissance'}\n",
      "{'Backdoor', 'Fuzzers', 'Worms', 'Generic', 'DoS', 'Exploits', 'Normal', 'Reconnaissance'}\n",
      "80595\n",
      "35178\n"
     ]
    }
   ],
   "source": [
    "#Removes categorical values not present in both datasets\n",
    "categorical_columns = ['proto', 'service', 'state', 'attack_cat']\n",
    "\n",
    "for column in categorical_columns:\n",
    "    unique_values_training = set(df_training_set[column].unique())\n",
    "    unique_values_test = set(df_test_set[column].unique())\n",
    "\n",
    "    print(unique_values_training)\n",
    "    print(unique_values_test)\n",
    "    \n",
    "    common_values = unique_values_training.intersection(unique_values_test)\n",
    "    print(common_values)\n",
    "\n",
    "    df_training_set = df_training_set[df_training_set[column].isin(common_values)]\n",
    "    df_test_set = df_test_set[df_test_set[column].isin(common_values)]\n",
    "\n",
    "print(len(df_training_set))\n",
    "print(len(df_test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns 'id' and 'is_sm_ips_ports' are dropped from the dataframes: 'id' is irrelevent to the data at hand, and 'is_sm_ips_ports' causes errors when calculating z scores (likely because it is always 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training_set.drop('id', axis = 1, inplace = True)\n",
    "df_training_set.drop('is_sm_ips_ports', axis = 1, inplace = True)\n",
    "\n",
    "df_test_set.drop('id', axis = 1, inplace = True)\n",
    "df_test_set.drop('is_sm_ips_ports', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numerical data is then normalized via z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finds numerical data (columns that are not categorical)\n",
    "numerical_columns = set(df_training_set.columns.symmetric_difference(categorical_columns))\n",
    "\n",
    "from scipy.stats import zscore\n",
    "\n",
    "def z_score_numerical(df, names):\n",
    "    for name in names:\n",
    "        df[name] = zscore(df[name])\n",
    "\n",
    "z_score_numerical(df_training_set, numerical_columns)\n",
    "z_score_numerical(df_test_set, numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the next bit of code encodes the now-filtered categorical values into their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue) given a dataframe and a list of column names\n",
    "def encode_text_dummy_loop(df, names):\n",
    "    for name in names:\n",
    "        dummies = pd.get_dummies(df[name])\n",
    "        for x in dummies.columns:\n",
    "            dummy_name = \"{}-{}\".format(name, x)\n",
    "            df[dummy_name] = dummies[x]\n",
    "        df.drop(name, axis=1, inplace=True)\n",
    "\n",
    "encode_text_dummy_loop(df_training_set, categorical_columns)\n",
    "encode_text_dummy_loop(df_test_set, categorical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is now ready for processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the Data\n",
    "Split data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (60879, 43)\n",
      "Test set shape: (35179, 43)\n"
     ]
    }
   ],
   "source": [
    "# Ensure both sets have the same columns after encoding\n",
    "df_training_set, df_test_set = df_training_set.align(df_test_set, join='inner', axis=1)\n",
    "\n",
    "# Features (X) and Target (y)\n",
    "X_train = df_training_set.drop(columns=['label'])\n",
    "y_train = df_training_set['label']\n",
    "X_test = df_test_set.drop(columns=['label'])\n",
    "y_test = df_test_set['label']\n",
    "\n",
    "# Split training data for validation\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
    "\n",
    "# Check data shapes\n",
    "print(f'Training set shape: {X_train_split.shape}')\n",
    "print(f'Test set shape: {X_test.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
